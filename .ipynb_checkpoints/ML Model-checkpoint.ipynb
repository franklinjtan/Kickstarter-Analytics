{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae815263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ee7e2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../inputs/kickstarter_projects.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_62456\\293552190.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Load the CSV dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'../inputs/kickstarter_projects.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    676\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    677\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 678\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    679\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    680\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 575\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    576\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    577\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    930\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    931\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 932\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    933\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    934\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1214\u001B[0m             \u001B[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1215\u001B[0m             \u001B[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1216\u001B[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001B[0m\u001B[0;32m   1217\u001B[0m                 \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1218\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    784\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    785\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 786\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    787\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    788\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../inputs/kickstarter_projects.csv'"
     ]
    }
   ],
   "source": [
    "# Load the CSV dataset\n",
    "df = pd.read_csv('../inputs/kickstarter_projects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ee679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 378661 entries, 0 to 378660\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   ID                378661 non-null  int64         \n",
      " 1   name              378657 non-null  object        \n",
      " 2   category          378661 non-null  object        \n",
      " 3   main_category     378661 non-null  object        \n",
      " 4   currency          378661 non-null  object        \n",
      " 5   deadline          378661 non-null  datetime64[ns]\n",
      " 6   goal              378661 non-null  float64       \n",
      " 7   launched          378661 non-null  datetime64[ns]\n",
      " 8   pledged           378661 non-null  float64       \n",
      " 9   state             378661 non-null  object        \n",
      " 10  backers           378661 non-null  int64         \n",
      " 11  country           378661 non-null  object        \n",
      " 12  usd pledged       374864 non-null  float64       \n",
      " 13  usd_pledged_real  378661 non-null  float64       \n",
      " 14  usd_goal_real     378661 non-null  float64       \n",
      " 15  year_deadline     378661 non-null  int64         \n",
      " 16  month_deadline    378661 non-null  int64         \n",
      " 17  year_launched     378661 non-null  int64         \n",
      " 18  month_launched    378661 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(5), int64(6), object(6)\n",
      "memory usage: 54.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert to Datetime and Split Date Parts\n",
    "df['deadline'] = pd.to_datetime(df['deadline'])\n",
    "df['launched'] = pd.to_datetime(df['launched'])\n",
    "\n",
    "# Extract Year, Month, Day, and Hour Fields from Deadline\n",
    "df['year_deadline'] = df['deadline'].dt.year\n",
    "df['month_deadline'] = df['deadline'].dt.month\n",
    "\n",
    "\n",
    "# Extract Year, Month, Day, and Hour Fields from \n",
    "df['year_launched'] = df['launched'].dt.year\n",
    "df['month_launched'] = df['launched'].dt.month\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "611c67cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 378661 entries, 0 to 378660\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   ID                   378661 non-null  int64         \n",
      " 1   name                 378657 non-null  object        \n",
      " 2   category             378661 non-null  object        \n",
      " 3   main_category        378661 non-null  object        \n",
      " 4   currency             378661 non-null  object        \n",
      " 5   deadline             378661 non-null  datetime64[ns]\n",
      " 6   goal                 378661 non-null  float64       \n",
      " 7   launched             378661 non-null  datetime64[ns]\n",
      " 8   pledged              378661 non-null  float64       \n",
      " 9   state                378661 non-null  object        \n",
      " 10  backers              378661 non-null  int64         \n",
      " 11  country              378661 non-null  object        \n",
      " 12  usd pledged          374864 non-null  float64       \n",
      " 13  usd_pledged_real     378661 non-null  float64       \n",
      " 14  usd_goal_real        378661 non-null  float64       \n",
      " 15  year_deadline        378661 non-null  int64         \n",
      " 16  month_deadline       378661 non-null  int64         \n",
      " 17  year_launched        378661 non-null  int64         \n",
      " 18  month_launched       378661 non-null  int64         \n",
      " 19  year_month_deadline  378661 non-null  category      \n",
      " 20  year_month_launched  378661 non-null  category      \n",
      "dtypes: category(2), datetime64[ns](2), float64(5), int64(6), object(6)\n",
      "memory usage: 55.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Combine Year and Month Columns into a new Categorical Column 'Year_Month_deadline'\n",
    "df['year_month_deadline'] = df['year_deadline'].astype(str) + '-' + df['month_deadline'].astype(str)\n",
    "\n",
    "# Convert 'Year_Month_deadline' column to Categorical data type\n",
    "df['year_month_deadline'] = pd.Categorical(df['year_month_deadline'])\n",
    "\n",
    "# Combine Year and Month Columns into a new Categorical Column 'Year_Month_launched'\n",
    "df['year_month_launched'] = df['year_launched'].astype(str) + '-' + df['month_launched'].astype(str)\n",
    "\n",
    "# Convert 'Year_Month_launched' column to Categorical data type\n",
    "df['year_month_launched'] = pd.Categorical(df['year_month_launched'])\n",
    "\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9faf8f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    244705\n",
       "0    133956\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with Dependent Variable State\n",
    "df['target'] = df['state'].apply(lambda x: 0 if x == 'successful' else 1)\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb4b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Display to Show all Columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219784d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 374860 entries, 0 to 378660\n",
      "Data columns (total 22 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   ID                   374860 non-null  int64         \n",
      " 1   name                 374860 non-null  object        \n",
      " 2   category             374860 non-null  object        \n",
      " 3   main_category        374860 non-null  object        \n",
      " 4   currency             374860 non-null  object        \n",
      " 5   deadline             374860 non-null  datetime64[ns]\n",
      " 6   goal                 374860 non-null  float64       \n",
      " 7   launched             374860 non-null  datetime64[ns]\n",
      " 8   pledged              374860 non-null  float64       \n",
      " 9   state                374860 non-null  object        \n",
      " 10  backers              374860 non-null  int64         \n",
      " 11  country              374860 non-null  object        \n",
      " 12  usd pledged          374860 non-null  float64       \n",
      " 13  usd_pledged_real     374860 non-null  float64       \n",
      " 14  usd_goal_real        374860 non-null  float64       \n",
      " 15  year_deadline        374860 non-null  int64         \n",
      " 16  month_deadline       374860 non-null  int64         \n",
      " 17  year_launched        374860 non-null  int64         \n",
      " 18  month_launched       374860 non-null  int64         \n",
      " 19  year_month_deadline  374860 non-null  category      \n",
      " 20  year_month_launched  374860 non-null  category      \n",
      " 21  target               374860 non-null  int64         \n",
      "dtypes: category(2), datetime64[ns](2), float64(5), int64(7), object(6)\n",
      "memory usage: 60.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop NA\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51008858",
   "metadata": {},
   "source": [
    "Dropped NAs because there were few and wouldn't affect the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c84bb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create copy of df \n",
    "df2 = df.copy()\n",
    "\n",
    "# Perform one-hot encoding on categorical features\n",
    "#df_encoded = pd.get_dummies(df2, columns=['category', 'currency'])\n",
    "\n",
    "#df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972837f",
   "metadata": {},
   "source": [
    "Removed country from the ML analysis because it lacked variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "454fcf44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "286c45d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Film & Video    62696\n",
       "Music           49530\n",
       "Publishing      39379\n",
       "Games           35225\n",
       "Technology      32562\n",
       "Design          30066\n",
       "Art             28152\n",
       "Food            24599\n",
       "Fashion         22812\n",
       "Theater         10912\n",
       "Comics          10819\n",
       "Photography     10778\n",
       "Crafts           8809\n",
       "Journalism       4754\n",
       "Dance            3767\n",
       "Name: main_category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['main_category'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f818b9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product Design        22310\n",
       "Documentary           16138\n",
       "Tabletop Games        14178\n",
       "Music                 13340\n",
       "Shorts                12357\n",
       "Video Games           11828\n",
       "Food                  11492\n",
       "Film & Video           9224\n",
       "Fiction                9168\n",
       "Fashion                8554\n",
       "Nonfiction             8317\n",
       "Art                    8253\n",
       "Apparel                7165\n",
       "Theater                7056\n",
       "Technology             6927\n",
       "Rock                   6758\n",
       "Children's Books       6756\n",
       "Apps                   6345\n",
       "Webseries              5762\n",
       "Photography            5752\n",
       "Indie Rock             5657\n",
       "Publishing             5525\n",
       "Narrative Film         5186\n",
       "Web                    5153\n",
       "Comics                 4996\n",
       "Crafts                 4664\n",
       "Country & Folk         4451\n",
       "Design                 4199\n",
       "Hip-Hop                3911\n",
       "Hardware               3662\n",
       "Pop                    3350\n",
       "Painting               3293\n",
       "Games                  3225\n",
       "Illustration           3175\n",
       "Accessories            3162\n",
       "Public Art             3077\n",
       "Software               3046\n",
       "Gadgets                2965\n",
       "Restaurants            2818\n",
       "Mixed Media            2757\n",
       "Comic Books            2743\n",
       "Art Books              2676\n",
       "Classical Music        2613\n",
       "Animation              2541\n",
       "Playing Cards          2496\n",
       "Drinks                 2422\n",
       "Dance                  2321\n",
       "Comedy                 2320\n",
       "Drama                  2178\n",
       "Electronic Music       2170\n",
       "Performance Art        2154\n",
       "World Music            2102\n",
       "Graphic Design         2002\n",
       "Graphic Novels         1864\n",
       "Jazz                   1850\n",
       "Sculpture              1810\n",
       "Small Batch            1808\n",
       "Mobile Games           1789\n",
       "Food Trucks            1752\n",
       "Journalism             1747\n",
       "Photobooks             1580\n",
       "Plays                  1378\n",
       "Poetry                 1369\n",
       "Digital Art            1346\n",
       "Horror                 1286\n",
       "Periodicals            1265\n",
       "Jewelry                1239\n",
       "Wearables              1233\n",
       "DIY                    1173\n",
       "Woodworking            1167\n",
       "Farms                  1154\n",
       "People                 1103\n",
       "Faith                  1092\n",
       "Live Games             1050\n",
       "Conceptual Art         1030\n",
       "Television             1015\n",
       "Performances           1013\n",
       "Footwear                931\n",
       "Experimental            924\n",
       "Radio & Podcasts        923\n",
       "Academic                916\n",
       "Musical                 913\n",
       "DIY Electronics         902\n",
       "Ready-to-wear           864\n",
       "Spaces                  841\n",
       "Festivals               839\n",
       "Young Adult             821\n",
       "Events                  817\n",
       "Anthologies             784\n",
       "Fine Art                775\n",
       "Architecture            760\n",
       "Thrillers               746\n",
       "Science Fiction         744\n",
       "Action                  740\n",
       "Places                  739\n",
       "Print                   726\n",
       "Metal                   717\n",
       "Music Videos            709\n",
       "3D Printing             682\n",
       "Sound                   669\n",
       "Webcomics               648\n",
       "Vegan                   588\n",
       "Nature                  574\n",
       "Robots                  572\n",
       "Cookbooks               540\n",
       "Childrenswear           483\n",
       "Installations           482\n",
       "R&B                     458\n",
       "Candles                 429\n",
       "Gaming Hardware         428\n",
       "Video                   428\n",
       "Flight                  426\n",
       "Farmer's Markets        424\n",
       "Camera Equipment        416\n",
       "Audio                   410\n",
       "Interactive Design      398\n",
       "Zines                   391\n",
       "Fantasy                 345\n",
       "Family                  336\n",
       "Immersive               330\n",
       "Calendars               329\n",
       "Space Exploration       323\n",
       "Punk                    317\n",
       "Ceramics                305\n",
       "Community Gardens       298\n",
       "Civic Design            289\n",
       "Kids                    285\n",
       "Literary Journals       278\n",
       "Textiles                276\n",
       "Couture                 275\n",
       "Blues                   268\n",
       "Animals                 255\n",
       "Fabrication Tools       250\n",
       "Makerspaces             238\n",
       "Printing                238\n",
       "Movie Theaters          232\n",
       "Puzzles                 231\n",
       "Bacon                   221\n",
       "Stationery              219\n",
       "Photo                   196\n",
       "Video Art               194\n",
       "Romance                 190\n",
       "Knitting                181\n",
       "Workshops               164\n",
       "Crochet                 162\n",
       "Translations            153\n",
       "Pet Fashion             139\n",
       "Glass                   138\n",
       "Latin                   137\n",
       "Embroidery              113\n",
       "Typography              108\n",
       "Pottery                 100\n",
       "Weaving                  93\n",
       "Quilts                   81\n",
       "Residencies              69\n",
       "Letterpress              49\n",
       "Chiptune                 35\n",
       "Literary Spaces          27\n",
       "Taxidermy                13\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df2['category'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03dfa2d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 374860 entries, 0 to 378660\n",
      "Data columns (total 22 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   ID                   374860 non-null  int64         \n",
      " 1   name                 374860 non-null  object        \n",
      " 2   category             374860 non-null  object        \n",
      " 3   main_category        374860 non-null  object        \n",
      " 4   currency             374860 non-null  object        \n",
      " 5   deadline             374860 non-null  datetime64[ns]\n",
      " 6   goal                 374860 non-null  float64       \n",
      " 7   launched             374860 non-null  datetime64[ns]\n",
      " 8   pledged              374860 non-null  float64       \n",
      " 9   state                374860 non-null  object        \n",
      " 10  backers              374860 non-null  int64         \n",
      " 11  country              374860 non-null  object        \n",
      " 12  usd pledged          374860 non-null  float64       \n",
      " 13  usd_pledged_real     374860 non-null  float64       \n",
      " 14  usd_goal_real        374860 non-null  float64       \n",
      " 15  year_deadline        374860 non-null  int64         \n",
      " 16  month_deadline       374860 non-null  int64         \n",
      " 17  year_launched        374860 non-null  int64         \n",
      " 18  month_launched       374860 non-null  int64         \n",
      " 19  year_month_deadline  374860 non-null  category      \n",
      " 20  year_month_launched  374860 non-null  category      \n",
      " 21  target               374860 non-null  int64         \n",
      "dtypes: category(2), datetime64[ns](2), float64(5), int64(7), object(6)\n",
      "memory usage: 60.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "631c06f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "backers: -0.02067775384523369\n",
      "usd_pledged_real: -0.001056202267435351\n",
      "usd_goal_real: 0.001048130237525573\n",
      "year_launched: -0.0001626217007981502\n",
      "month_launched: 0.013355302445678438\n",
      "main_category_Art: -0.09040546982320143\n",
      "main_category_Comics: -0.028661871371666692\n",
      "main_category_Crafts: 0.21126408168908992\n",
      "main_category_Dance: -0.13497635176299225\n",
      "main_category_Design: 0.24104513373881523\n",
      "main_category_Fashion: 0.3021326524399457\n",
      "main_category_Film & Video: -0.6287187315908501\n",
      "main_category_Food: 0.1742161123861222\n",
      "main_category_Games: 0.45414188552759593\n",
      "main_category_Journalism: 0.05948100297116102\n",
      "main_category_Music: -0.6204136651612973\n",
      "main_category_Photography: 0.06790141383565872\n",
      "main_category_Publishing: 0.12395281607030141\n",
      "main_category_Technology: 0.2647224910523956\n",
      "main_category_Theater: -0.3982926820425674\n",
      "\n",
      "Classification Metrics:\n",
      "Precision: 1.00\n",
      "Accuracy: 0.96\n",
      "Recall: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "# Perform one-hot encoding on categorical features\n",
    "df_encoded = pd.get_dummies(df2, columns=['main_category', \n",
    "                                          #'currency', \n",
    "                                          #'year_month_deadline', \n",
    "                                          #'year_month_launched', \n",
    "                                         ])\n",
    "\n",
    "# Prepare the feature matrix X and the target variable y\n",
    "X = df_encoded.drop(['target',\n",
    "                     'ID',\n",
    "                     'name',\n",
    "                     'goal',\n",
    "                     #'main_category',\n",
    "                     'category',\n",
    "                     'deadline',\n",
    "                     'launched',\n",
    "                     'pledged',\n",
    "                     'state',\n",
    "                     'country', \n",
    "                     'usd pledged',\n",
    "                     'year_deadline',\n",
    "                     'month_deadline',\n",
    "                     'year_month_deadline',\n",
    "                     'year_month_launched',\n",
    "                     'currency'\n",
    "                     #'year_launched',\n",
    "                     #'month_launched',\n",
    "                    ], axis=1)  # Drop Irrelevant Columns\n",
    "y = df_encoded['target']  # Assign the target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Calculate class weights\n",
    "#class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "\n",
    "# Perform Logistic Regression with class weights\n",
    "logreg = LogisticRegression(class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "########################\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "# Get feature importances (coefficients) from the logistic regression model\n",
    "feature_importance = logreg.coef_[0]\n",
    "\n",
    "# Print feature importances (you can also plot them if you prefer)\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(X.columns, feature_importance):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute classification metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nClassification Metrics:\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b228a504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "backers: -0.02067775384523369\n",
      "usd_pledged_real: -0.001056202267435351\n",
      "usd_goal_real: 0.001048130237525573\n",
      "year_launched: -0.0001626217007981502\n",
      "month_launched: 0.013355302445678438\n",
      "main_category_Art: -0.09040546982320143\n",
      "main_category_Comics: -0.028661871371666692\n",
      "main_category_Crafts: 0.21126408168908992\n",
      "main_category_Dance: -0.13497635176299225\n",
      "main_category_Design: 0.24104513373881523\n",
      "main_category_Fashion: 0.3021326524399457\n",
      "main_category_Film & Video: -0.6287187315908501\n",
      "main_category_Food: 0.1742161123861222\n",
      "main_category_Games: 0.45414188552759593\n",
      "main_category_Journalism: 0.05948100297116102\n",
      "main_category_Music: -0.6204136651612973\n",
      "main_category_Photography: 0.06790141383565872\n",
      "main_category_Publishing: 0.12395281607030141\n",
      "main_category_Technology: 0.2647224910523956\n",
      "main_category_Theater: -0.3982926820425674\n",
      "\n",
      "Classification Metrics:\n",
      "Accuracy: 0.96\n",
      "Precision: 1.00\n",
      "Recall: 0.94\n",
      "AUC: 0.97\n",
      "F1 Score: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylanjuarez/opt/anaconda3/envs/Dyl_Python_Env/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py:1819: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: inf\n",
      "         Iterations 16\n",
      "\n",
      "Significant Features (p-value < 0.05):\n",
      "Index(['backers', 'usd_pledged_real', 'usd_goal_real', 'year_launched',\n",
      "       'month_launched'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylanjuarez/opt/anaconda3/envs/Dyl_Python_Env/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py:1872: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def logistic_regression_with_pvalues(X_train, y_train, X_test, y_test):\n",
    "    # Calculate class weights\n",
    "    #class_counts = y_train.value_counts()\n",
    "    #class_weight_0 = class_counts[1] / (class_counts[0] + class_counts[1])\n",
    "    #class_weight_1 = class_counts[0] / (class_counts[0] + class_counts[1])\n",
    "\n",
    "    # Perform Logistic Regression with class weights\n",
    "    logreg = LogisticRegression(class_weight='balanced')\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importances (coefficients) from the logistic regression model\n",
    "    feature_importance = logreg.coef_[0]\n",
    "\n",
    "    # Print feature importances (you can also plot them if you prefer)\n",
    "    print(\"Feature Importances:\")\n",
    "    for feature, importance in zip(X_train.columns, feature_importance):\n",
    "        print(f\"{feature}: {importance}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Compute classification metrics\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nClassification Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"AUC: {auc:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "    # Fit logistic regression using statsmodels to get p-values\n",
    "    X_train_with_constant = sm.add_constant(X_train)\n",
    "    logit_model = sm.Logit(y_train, X_train_with_constant)\n",
    "    result = logit_model.fit()\n",
    "\n",
    "    # Filter features with p-values < 0.05\n",
    "    significant_features = result.pvalues[1:].index[result.pvalues[1:] < 0.05]\n",
    "    print(\"\\nSignificant Features (p-value < 0.05):\")\n",
    "    print(significant_features)\n",
    "\n",
    "# Assuming you already have X_train, X_test, y_train, y_test from the previous code\n",
    "logistic_regression_with_pvalues(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e293975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
